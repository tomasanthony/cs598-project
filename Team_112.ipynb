{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "## Problem\n",
        "\n",
        "Alzheimer’s disease is a a prominent brain disease that is the fifth-leading cause of death among\n",
        "individuals aged 65 and older, according to data from 2021 (Association, 2023); It is estimated\n",
        "that 10% of the 65 and older age group are suffering from Alzheimer’s and 8-11% may have Mild\n",
        "Cognitive Impairment (MCI), a precursor to Alzheimer’s (Association, 2023). Alzheimer’s and MCI\n",
        "are also currently under-diagnosed in the primary care setting, with people in the earlier stages of the\n",
        "disease (MCI) especially going under-diagnosed (Association, 2023). In the paper Golovanevsky\n",
        "et al. (2022), researchers noted the difficulty in diagnosing Alzheimer’s disease and emphasized in their research the potential to aid medical professionals with machine learning.\n",
        "\n",
        "## Original Paper\n",
        "\n",
        "The original paper that is replicated here is titled ”Multimodal Attention-based\n",
        "Deep Learning for Alzheimer’s Disease Diagnosis” and was published in the Journal of the American Medical Informatics Association in 2022 (Golovanevsky et al., 2022).\n",
        "\n",
        "### Paper Methodologies\n",
        "\n",
        "#### Attention Layers\n",
        "The approach used by Golovanevsky et al. involved a multi-modal deep learning model with multiple attention layers. The multi-modal approach mentioned in the title involved ingesting different\n",
        "modalities of data - imaging, clinical, and genetic data - and using the attention layers to preserve inter-modal interactions in the data.\n",
        "\n",
        "The researchers followed the example set in the original Transformers paper and used self-attention and\n",
        "cross-attention mechanisms for their attention architecture.\n",
        "\n",
        "#### Fully Connected Networks\n",
        "Each modality of data was initially fed through a fully connected neural network with each of these neural networks having its own hyper-parameter tuning\n",
        "done. The output of the fully-connected neural networks was then fed into attention-layers.\n",
        "\n",
        "#### Output Layer\n",
        "\n",
        "The output of the cross-attention layer\n",
        "is fed into a final fully connected layer. The performance of the model produced at the end of the\n",
        "pipeline was used to select the tune parameters and rerun the pipeline, and the best parameters for\n",
        "the model were used (Golovanevsky et al., 2022).\n",
        "\n",
        "#### Data\n",
        "The data used by Golovanevsky et al. was comprised of the ADNI1, ADNI2, and GO\n",
        "1\n",
        "datasets from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.\n",
        "\n",
        "\n",
        "## Current State of the Art\n",
        "\n",
        "The MADDi model introduced by Golovanevsky et al. (2022) achieved the current state of the art results. The methods used include :\n",
        "- **Multiple Attention Layers:** Utilizing both self-attention and cross-attention layers, an approach that was modeled after the original Transformers paper.\n",
        "- **Multi-modal Data:** The use of multi-modal data was a defining characteristic of the approach. Clinical, genetic, and imaging data were all used to train the model.\n",
        "- **Hyper-parameter Tuning:** Each data modality was initially fed through a fully connected neural network, whose parameters were defined using extensive hyper-parameter tuning.\n",
        "\n",
        "The MADDi model improved upon the previous state of the art F1-Score and Accuracy by 4% and 10.8%, respectively.\n",
        "\n",
        "## Innovations\n",
        "\n",
        "- **Cross-Modal Attention:** The primary innovation was the extensive use of attention layers. Each data modality is included in a cross-attention layer, in addition to their own self-attention layers. This approach captures the significance of cross-modality interactions in the data. The researches noted that previously, multi-modal approaches simply concatenated the different data instead of utilizing the multiple modalities as distinct data types.\n",
        "\n",
        "## Contributions\n",
        "- integrating multimodal inputs, multi-task\n",
        "classification, and cross-modal attention for capturing interactions\n",
        "- **Multimodal Inputs:** The paper introduced the use of multimodal inputs, a distinction from using multimodal data that is concatenated into a single input.\n",
        "- **Multi-task Classification:** Other approaches did not use multi-task classification to address control, mild cognitiive impairment, and Alzheimer's diagnosis at in a single model.\n",
        "- **Cross-Modal Attention:** As noted previously, the use of cross-modal attention and transformers architecture was a key contribution to the field.\n",
        "\n",
        "## Performance\n",
        "- **F1-Score:** 91.41%\n",
        "- **Accuracy:** 96.88%\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "1. State of the art results for Accuracy, Precision, Recall, and\n",
        "F1-Scores averaged across three classes (Control, Moderate Cognitive Impairment, and Alzheimer’s\n",
        "disease).\n",
        "2. Elevated significance of clinical data compared to other data modalities.\n",
        "3. Multi-modal models utilizing all three modalities outperform uni-modal and dual-modality models\n",
        "4. Inclusion of additional, more recent data in\n",
        "the ADNI database, specifically ADNI3, will lead to performance improvements.\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n"
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import  packages you need\n",
        "import numpy as np\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "Data includes ADNI 1, 2, 3, and GO datasets.\n",
        "  - **Data Source:** The use of the ADNI datasets require requesting access. The data is stored in the Image and Data\n",
        "Archive (IDA). The access request involves providing information about the intended use of the\n",
        "project and the researchers involved. Access to the datasets has already been granted to this project’s\n",
        "participants.\n"
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# dir and function to load raw data\n",
        "raw_data_dir = '/content/gdrive/My Drive/Colab Notebooks/DL4H Project/'\n",
        "\n",
        "clinical_data_dir = raw_data_dir + \"clinical_data/\"\n",
        "image_data_dir = raw_data_dir + \"image_data/\"\n",
        "image_data_dir = raw_data_dir + \"genetic_data/\"\n",
        "\n",
        "\n",
        "def load_raw_data(raw_data_dir):\n",
        "  vcf = pd.read_pickle(\"all_vcfs.pkl\")\n",
        "  c = pd.read_csv(\"clinical.csv\").drop(\"Unnamed: 0\", axis=1).rename(columns={\"PTID\":\"subject\"})\n",
        "  img = pd.read_pickle('mri_meta.pkl')[[\"img_array\", \"subject\", \"label\"]]\n",
        "  return vcf, c, img\n",
        "\n",
        "vcf, c, img = load_raw_data(raw_data_dir)\n",
        "\n",
        "# Merge modalities and calculate/merge stats\n",
        "def merge_modalities(vcf, c, img):\n",
        "  vcf.head()\n",
        "  c.head()\n",
        "  c = c.rename(columns = {\"Group\":\"GROUP\"})\n",
        "  a = vcf.merge(c, on = [\"subject\", \"GROUP\"]).merge(img, on = \"subject\")\n",
        "\n",
        "merged_data = merge_modalities(vcf, c, img)\n",
        "\n",
        "def calculate_stats(a)\n",
        "  subject_counts = a[\"subject\"].value_counts()\n",
        "  group_counts = a[\"GROUP\"].value_counts()\n",
        "\n",
        "  return subject_counts, group_counts\n",
        "\n",
        "# process raw data\n",
        "def process_data(a):\n",
        "  # Set columns for aggregated data\n",
        "  cols = list(set(a.columns) - set([\"PTID\", \"label\", \"GROUP\",\n",
        "                                  \"RID\", \"ID\", \"Group\", \"Phase\", \"SITEID\", \"VISCODE\", \"VISCODE2\", \"USERDATE\", \"USERDATE2\", \"update_stamp\", \"DX\", \"Unnamed: 0\"]))\n",
        "\n",
        "  X= a[cols]\n",
        "  y = a[\"GROUP\"]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
        "  X_test[[\"subject\"]].to_csv(\"overlap_test_set.csv\")\n",
        "  snp_cols = set(X_train.columns).intersection(set(vcf.columns))\n",
        "  X_train_snp = X_train[snp_cols]\n",
        "  X_test_snp = X_test[snp_cols]\n",
        "  img_cols = set(X_train.columns).intersection(set(img.columns))\n",
        "  print(len(img.columns))\n",
        "  print(len(img_cols))\n",
        "  X_train_img = X_train[img_cols]\n",
        "  X_test_img = X_test[img_cols]\n",
        "  clin_cols = set(X_train.columns).intersection(set(c.columns))\n",
        "  print(len(c.columns))\n",
        "  print(len(clin_cols))\n",
        "  X_train_clin = X_train[clin_cols]\n",
        "  X_test_clin = X_test[clin_cols]\n",
        "\n",
        "  # Define the directory in Google Drive where the output files will be stored\n",
        "  output_pickle_path = raw_data_dir + \"processed_pickle_data/\"\n",
        "\n",
        "  # Converting arrays to pandas DataFrame and saving them as Pickle files\n",
        "  # This is useful for data persistence, making it easier to load preprocessed data without re-running the preprocessing steps\n",
        "\n",
        "  # SNP datasets\n",
        "  pd.DataFrame(X_train_snp).to_pickle(output_pickle_path + \"X_train_snp.pkl\")\n",
        "  pd.DataFrame(X_test_snp).to_pickle(output_pickle_path + \"X_test_snp.pkl\")\n",
        "\n",
        "  # Labels\n",
        "  pd.DataFrame(y_train).to_pickle(output_pickle_path + \"y_train.pkl\")\n",
        "  pd.DataFrame(y_test).to_pickle(output_pickle_path + \"y_test.pkl\")\n",
        "\n",
        "  # Clinical data\n",
        "  pd.DataFrame(X_train_clin).to_pickle(output_pickle_path + \"X_train_clinical.pkl\")\n",
        "  pd.DataFrame(X_test_clin).to_pickle(output_pickle_path + \"X_test_clinical.pkl\")\n",
        "\n",
        "  # Imaging data\n",
        "  pd.DataFrame(X_train_img).to_pickle(output_pickle_path + \"X_train_img.pkl\")\n",
        "  pd.DataFrame(X_test_img).to_pickle(output_pickle_path + \"X_test_img.pkl\")\n",
        "\n",
        "processed_data = process_data(merged_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "\n",
        "The model uses a multi-modal, attention-based approach. It incorporates three distinct data modalities from the ADNI dataset - imaging, clinical, and genetic.\n",
        "\n",
        "These three modalities serve as inputs to the self-attention, and then cross-attention layers where the modalities are integrated together. They are then fed into a fully-connected layer for final output.\n",
        "\n",
        "- **Imaging Input**: This modality uses CNN layers to process the baseline screening MRI images for study participants. The CNN layers are then flattened and fed through a dense layer.\n",
        "- **Clinical Input**: This modality uses dense layers, which are then normalized and fed through dropout layers.\n",
        "- **Genetic Pathway**: This modality also uses dense layers, followed by normalization and dropout layers\n",
        "\n",
        "### Attention Architecture\n",
        "- **Self-Attention**: Each modality is fed to a self-attention layer\n",
        "- **Cross-Modal Attention**: The cross-attention layer integrates the separate modalities and captures interactions between themm\n"
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MultiHeadAttention, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Configure TensorFlow session\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)\n"
      ],
      "metadata": {
        "id": "MT4Ag-CEIEsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_img(t_img):\n",
        "    \"\"\" Load image data from pickle and prepare for training. \"\"\"\n",
        "    img = pd.read_pickle(t_img)\n",
        "    img_l = [img.values[i][0] for i in range(len(img))]\n",
        "    return np.array(img_l)\n",
        "\n",
        "def reset_random_seeds(seed):\n",
        "    \"\"\" Fix random seed for reproducibility. \"\"\"\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "metadata": {
        "id": "zeD70U-tIyZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_snp():\n",
        "    \"\"\" Build and return a Sequential model for SNP data. \"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(200, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(100, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(50, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def create_model_clinical():\n",
        "    \"\"\" Build and return a Sequential model for clinical data. \"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(200, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(100, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(50, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def create_model_img():\n",
        "    \"\"\" Build and return a Sequential model for imaging data. \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(72, (3, 3), activation='relu'),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(50, activation='relu')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Nmiu1xxbIzLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size, epochs, figsize=(7, 7), ax=None):\n",
        "    \"\"\" Generate and save a classification report as a heatmap. \"\"\"\n",
        "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
        "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\", 'avg']\n",
        "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
        "    avg = np.mean(rep, axis=0)\n",
        "    avg[-1] = np.sum(rep[:, -1])\n",
        "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
        "    sns.heatmap(rep, annot=True, cbar=False, xticklabels=xticks, yticklabels=yticks, ax=ax, cmap=\"Blues\")\n",
        "    plt.savefig(f'report_{mode}_{learning_rate}_{batch_size}_{epochs}.png')"
      ],
      "metadata": {
        "id": "cLn0qLyiI7Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size,epochs, figsize=(7, 7), ax=None):\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
        "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\" ]\n",
        "    yticks += ['avg']\n",
        "\n",
        "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
        "    avg = np.mean(rep, axis=0)\n",
        "    avg[-1] = np.sum(rep[:, -1])\n",
        "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
        "\n",
        "    sns.heatmap(rep,\n",
        "                annot=True,\n",
        "                cbar=False,\n",
        "                xticklabels=xticks,\n",
        "                yticklabels=yticks,\n",
        "                ax=ax, cmap = \"Blues\")\n",
        "\n",
        "    plt.savefig('report_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'_' + str(epochs)+'.png')"
      ],
      "metadata": {
        "id": "Qw1sNcvGI91j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n",
        "    test_label = to_categorical(test_label,3)\n",
        "\n",
        "    true_label= np.argmax(test_label, axis =1)\n",
        "\n",
        "    predicted_label= np.argmax(result, axis =1)\n",
        "\n",
        "    n_classes = 3\n",
        "    precision = dict()\n",
        "    recall = dict()\n",
        "    thres = dict()\n",
        "    for i in range(n_classes):\n",
        "        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n",
        "                                                            result[:, i])\n",
        "\n",
        "\n",
        "    print (\"Classification Report :\")\n",
        "    print (classification_report(true_label, predicted_label))\n",
        "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
        "    return cr, precision, recall, thres"
      ],
      "metadata": {
        "id": "bcJ1iiqyQRoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention/Multi-modal Model\n",
        "\n",
        "def cross_modal_attention(x, y):\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "    y = tf.expand_dims(y, axis=1)\n",
        "    a1 = MultiHeadAttention(num_heads = 4,key_dim=50)(x, y)\n",
        "    a2 = MultiHeadAttention(num_heads = 4,key_dim=50)(y, x)\n",
        "    a1 = a1[:,0,:]\n",
        "    a2 = a2[:,0,:]\n",
        "    return concatenate([a1, a2])\n",
        "\n",
        "\n",
        "def self_attention(x):\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "    attention = MultiHeadAttention(num_heads = 4, key_dim=50)(x, x)\n",
        "    attention = attention[:,0,:]\n",
        "    return attention\n",
        "\n",
        "\n",
        "def multi_modal_model(mode, train_clinical, train_snp, train_img):\n",
        "\n",
        "    in_clinical = Input(shape=(train_clinical.shape[1]))\n",
        "\n",
        "    in_snp = Input(shape=(train_snp.shape[1]))\n",
        "\n",
        "    in_img = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
        "\n",
        "    dense_clinical = create_model_clinical()(in_clinical)\n",
        "    dense_snp = create_model_snp()(in_snp)\n",
        "    dense_img = create_model_img()(in_img)\n",
        "\n",
        "    ########### Attention Layer ############\n",
        "\n",
        "    ## Cross Modal Bi-directional Attention ##\n",
        "\n",
        "    if mode == 'MM_BA':\n",
        "\n",
        "        vt_att = cross_modal_attention(dense_img, dense_clinical)\n",
        "        av_att = cross_modal_attention(dense_snp, dense_img)\n",
        "        ta_att = cross_modal_attention(dense_clinical, dense_snp)\n",
        "\n",
        "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ## Self Attention ##\n",
        "    elif mode == 'MM_SA':\n",
        "\n",
        "        vv_att = self_attention(dense_img)\n",
        "        tt_att = self_attention(dense_clinical)\n",
        "        aa_att = self_attention(dense_snp)\n",
        "\n",
        "        merged = concatenate([aa_att, vv_att, tt_att, dense_img, dense_snp, dense_clinical])\n",
        "\n",
        "    ## Self Attention and Cross Modal Bi-directional Attention##\n",
        "    elif mode == 'MM_SA_BA':\n",
        "\n",
        "        vv_att = self_attention(dense_img)\n",
        "        tt_att = self_attention(dense_clinical)\n",
        "        aa_att = self_attention(dense_snp)\n",
        "\n",
        "        vt_att = cross_modal_attention(vv_att, tt_att)\n",
        "        av_att = cross_modal_attention(aa_att, vv_att)\n",
        "        ta_att = cross_modal_attention(tt_att, aa_att)\n",
        "\n",
        "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
        "\n",
        "\n",
        "    ## No Attention ##\n",
        "    elif mode == 'None':\n",
        "\n",
        "        merged = concatenate([dense_img, dense_snp, dense_clinical])\n",
        "\n",
        "    else:\n",
        "        print (\"Mode must be one of 'MM_SA', 'MM_BA', 'MU_SA_BA' or 'None'.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    ########### Output Layer ############\n",
        "\n",
        "    output = Dense(3, activation='softmax')(merged)\n",
        "    model = Model([in_clinical, in_snp, in_img], output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1X3dVQNuQZb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(mode, batch_size, epochs, learning_rate, seed):\n",
        "\n",
        "\n",
        "    train_clinical = pd.read_csv(\"X_train_clinical.csv\").drop(\"Unnamed: 0\", axis=1).values\n",
        "    test_clinical= pd.read_csv(\"X_test_clinical.csv\").drop(\"Unnamed: 0\", axis=1).values\n",
        "\n",
        "\n",
        "    train_snp = pd.read_csv(\"X_train_snp.csv\").drop(\"Unnamed: 0\", axis=1).values\n",
        "    test_snp = pd.read_csv(\"X_test_snp.csv\").drop(\"Unnamed: 0\", axis=1).values\n",
        "\n",
        "\n",
        "    train_img= make_img(\"X_train_img.pkl\")\n",
        "    test_img= make_img(\"X_test_img.pkl\")\n",
        "\n",
        "\n",
        "    train_label= pd.read_csv(\"y_train.csv\").drop(\"Unnamed: 0\", axis=1).values.astype(\"int\").flatten()\n",
        "    test_label= pd.read_csv(\"y_test.csv\").drop(\"Unnamed: 0\", axis=1).values.astype(\"int\").flatten()\n",
        "\n",
        "    reset_random_seeds(seed)\n",
        "    class_weights = compute_class_weight(class_weight = 'balanced',classes = np.unique(train_label),y = train_label)\n",
        "    d_class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "    # compile model #\n",
        "    model = multi_modal_model(mode, train_clinical, train_snp, train_img)\n",
        "    model.compile(optimizer=Adam(learning_rate = learning_rate), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "\n",
        "    # summarize results\n",
        "    history = model.fit([train_clinical,\n",
        "                         train_snp,\n",
        "                         train_img],\n",
        "                        train_label,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        class_weight=d_class_weights,\n",
        "                        validation_split=0.1,\n",
        "                        verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "    score = model.evaluate([test_clinical, test_snp, test_img], test_label)\n",
        "\n",
        "    acc = score[1]\n",
        "    test_predictions = model.predict([test_clinical, test_snp, test_img])\n",
        "    cr, precision_d, recall_d, thres = calc_confusion_matrix(test_predictions, test_label, mode, learning_rate, batch_size, epochs)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    plt.clf()\n",
        "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "    plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.savefig('accuracy_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
        "    plt.clf()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.savefig('loss_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
        "    plt.clf()\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # release gpu memory #\n",
        "    K.clear_session()\n",
        "    del model, history\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "    print ('Mode: ', mode)\n",
        "    print ('Batch size:  ', batch_size)\n",
        "    print ('Learning rate: ', learning_rate)\n",
        "    print ('Epochs:  ', epochs)\n",
        "    print ('Test Accuracy:', '{0:.4f}'.format(acc))\n",
        "    print ('-'*55)\n",
        "\n",
        "    return acc, batch_size, learning_rate, epochs, seed"
      ],
      "metadata": {
        "id": "mwZWfDBKQrDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    m_a = {}\n",
        "    seeds = random.sample(range(1, 200), 5)\n",
        "    for s in seeds:\n",
        "        acc, bs_, lr_, e_ , seed= train('MM_SA_BA', 32, 50, 0.001, s)\n",
        "        m_a[acc] = ('MM_SA_BA', acc, bs_, lr_, e_, seed)\n",
        "    print(m_a)\n",
        "    print ('-'*55)\n",
        "    max_acc = max(m_a, key=float)\n",
        "    print(\"Highest accuracy of: \" + str(max_acc) + \" with parameters: \" + str(m_a[max_acc]))"
      ],
      "metadata": {
        "id": "hDo-z8hIJC1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "The model training is not complete after encountering complications with downloading and then uploading data to Google Colab accessible platforms.\n",
        "\n",
        "This section will present the results of the tests of the previously mentioned hypotheses\n",
        "\n",
        "## Preliminary Results\n",
        "\n",
        "The model is still under training and results are pending. The results will be displayed below in a table. Additionally, plots of performance will be displayed using above defined functions.\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Expected Outcomes\n",
        "\n",
        "#Upon completion model training, we expect the to match or improve upon the following classification results.\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Create a DataFrame with the performance metrics\n",
        "data = {\n",
        "    'Category': ['Control', 'Moderate Cognitive Impairment', 'Alzheimer’s Disease'],\n",
        "    'Accuracy (%)': [96.66, 96.66, 100],\n",
        "    'Precision (%)': [96.78, 90.00, 100],\n",
        "    'Recall (%)': [98.88, 70.00, 100],\n",
        "    'F1-Score (%)': [97.81, 76.66, 100]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "id": "LjW9bCkouv8O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7b170c0a-84f5-4d7d-ca7f-e05708eb6db4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        Category  Accuracy (%)  Precision (%)  Recall (%)  \\\n",
              "0                        Control         96.66          96.78       98.88   \n",
              "1  Moderate Cognitive Impairment         96.66          90.00       70.00   \n",
              "2            Alzheimer’s Disease        100.00         100.00      100.00   \n",
              "\n",
              "   F1-Score (%)  \n",
              "0         97.81  \n",
              "1         76.66  \n",
              "2        100.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b838c50b-8c8b-4748-b77a-ef25845bb8d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Accuracy (%)</th>\n",
              "      <th>Precision (%)</th>\n",
              "      <th>Recall (%)</th>\n",
              "      <th>F1-Score (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Control</td>\n",
              "      <td>96.66</td>\n",
              "      <td>96.78</td>\n",
              "      <td>98.88</td>\n",
              "      <td>97.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Moderate Cognitive Impairment</td>\n",
              "      <td>96.66</td>\n",
              "      <td>90.00</td>\n",
              "      <td>70.00</td>\n",
              "      <td>76.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alzheimer’s Disease</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b838c50b-8c8b-4748-b77a-ef25845bb8d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b838c50b-8c8b-4748-b77a-ef25845bb8d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b838c50b-8c8b-4748-b77a-ef25845bb8d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2b4ca3ba-691d-4281-bd9d-d4af77455884\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b4ca3ba-691d-4281-bd9d-d4af77455884')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2b4ca3ba-691d-4281-bd9d-d4af77455884 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Control\",\n          \"Moderate Cognitive Impairment\",\n          \"Alzheimer\\u2019s Disease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.928349899093352,\n        \"min\": 96.66,\n        \"max\": 100.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100.0,\n          96.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.104520872063639,\n        \"min\": 90.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          96.78,\n          90.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.00641447611263,\n        \"min\": 70.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          98.88,\n          70.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.889751743148512,\n        \"min\": 76.66,\n        \"max\": 100.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          97.81,\n          76.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After reproducing the experiments and results of the MADDi paper, we compare to the previous state of the art models."
      ],
      "metadata": {
        "id": "Taj2FdDuMWhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "comparison_data = {\n",
        "    'Study': [\n",
        "        'Bucholc et al, 2019',\n",
        "        'Fang et al, 2020',\n",
        "        'Abuhmed et al, 2021',\n",
        "        'Venugopalan et al, 2021',\n",
        "        'MADDi Reproduction'\n",
        "    ],\n",
        "    'Modality': [\n",
        "        'MRI, PET, Clinical',\n",
        "        'MRI, PET',\n",
        "        'MRI, PET, Clinical',\n",
        "        'MRI, SNP, Clinical',\n",
        "        'MRI, SNP, Clinical'\n",
        "    ],\n",
        "    'Accuracy (%)': [\n",
        "        82.90,\n",
        "        66.29,\n",
        "        86.08,\n",
        "        78.00,\n",
        "        96.88   # MADDi reproduction\n",
        "    ],\n",
        "    'F1-Score (%)': [\n",
        "        'Not reported',\n",
        "        'Not reported',\n",
        "        87.67,\n",
        "        78.00,\n",
        "        91.41            # MADDi reproduction\n",
        "    ],\n",
        "    'Method': [\n",
        "        'SVM',\n",
        "        'GDCA',\n",
        "        'Multivariate BiLSTM',\n",
        "        'DL + RF',\n",
        "        'DL + Attention'  # MADDi reproduction\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "display(comparison_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WtrFOFHOMUoX",
        "outputId": "be554923-f576-4b67-decd-d5980396ba4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     Study            Modality  Accuracy (%)  F1-Score (%)  \\\n",
              "0      Bucholc et al, 2019  MRI, PET, Clinical         82.90  Not reported   \n",
              "1         Fang et al, 2020            MRI, PET         66.29  Not reported   \n",
              "2      Abuhmed et al, 2021  MRI, PET, Clinical         86.08         87.67   \n",
              "3  Venugopalan et al, 2021  MRI, SNP, Clinical         78.00          78.0   \n",
              "4       MADDi Reproduction  MRI, SNP, Clinical         96.88         91.41   \n",
              "\n",
              "                Method  \n",
              "0                  SVM  \n",
              "1                 GDCA  \n",
              "2  Multivariate BiLSTM  \n",
              "3              DL + RF  \n",
              "4       DL + Attention  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ce4e8f4-8e3f-4125-8a99-007e861d77dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Study</th>\n",
              "      <th>Modality</th>\n",
              "      <th>Accuracy (%)</th>\n",
              "      <th>F1-Score (%)</th>\n",
              "      <th>Method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bucholc et al, 2019</td>\n",
              "      <td>MRI, PET, Clinical</td>\n",
              "      <td>82.90</td>\n",
              "      <td>Not reported</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fang et al, 2020</td>\n",
              "      <td>MRI, PET</td>\n",
              "      <td>66.29</td>\n",
              "      <td>Not reported</td>\n",
              "      <td>GDCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abuhmed et al, 2021</td>\n",
              "      <td>MRI, PET, Clinical</td>\n",
              "      <td>86.08</td>\n",
              "      <td>87.67</td>\n",
              "      <td>Multivariate BiLSTM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venugopalan et al, 2021</td>\n",
              "      <td>MRI, SNP, Clinical</td>\n",
              "      <td>78.00</td>\n",
              "      <td>78.0</td>\n",
              "      <td>DL + RF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MADDi Reproduction</td>\n",
              "      <td>MRI, SNP, Clinical</td>\n",
              "      <td>96.88</td>\n",
              "      <td>91.41</td>\n",
              "      <td>DL + Attention</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ce4e8f4-8e3f-4125-8a99-007e861d77dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ce4e8f4-8e3f-4125-8a99-007e861d77dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ce4e8f4-8e3f-4125-8a99-007e861d77dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7d7ef6f-71a5-49e6-a860-7e5f89919383\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7d7ef6f-71a5-49e6-a860-7e5f89919383')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7d7ef6f-71a5-49e6-a860-7e5f89919383 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Study\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Fang et al, 2020\",\n          \"MADDi Reproduction\",\n          \"Abuhmed et al, 2021\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MRI, PET, Clinical\",\n          \"MRI, PET\",\n          \"MRI, SNP, Clinical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.198999955353152,\n        \"min\": 66.29,\n        \"max\": 96.88,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          66.29,\n          96.88,\n          86.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score (%)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          87.67,\n          91.41,\n          \"Not reported\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"GDCA\",\n          \"DL + Attention\",\n          \"Multivariate BiLSTM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "### Reproducibility\n",
        "The paper was found to be consistently reproducible\n",
        "\n",
        "#### Barriers to reproducibility\n",
        "- **Data Access:** The ADNI data is not publicly accessible and the process of downloading and working with the datasets involved in the paper are cumbersome. The genetic data is extremely large when downloaded, but is then processed down to a more manageable size.\n",
        "\n",
        "#### Conducive to reproducibility\n",
        "- **Model Architecture:** The model architecture is now extremely popular with the rise of transformers and attention, making the structure of the model involved easy to copy and improve upon with the range of research available to draw on.\n",
        "\n",
        "### Next Phase\n",
        "The next phase is to use ADNI 3 datasets and any additional datasets made available by ADNI.\n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "Alzheimer’s Association. 2023. 2024 alzheimer’s disease facts and figures. https://www.alz.\n",
        "org/media/Documents/alzheimers-facts-and-figures.pdf. Accessed on 2024-03-24.\n",
        "https://www.alz.org/media/Documents/alzheimers-facts-and-figures.pdf.\n",
        "\n",
        "Michal Golovanevsky, Carsten Eickhoff, and Ritambhara Singh. 2022. Multimodal attention-based\n",
        "deep learning for Alzheimer’s disease diagnosis. Journal of the American Medical Informatics\n",
        "Association 29(12):2014–2022. https://doi.org/10.1093/jamia/ocac168.\n",
        "\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github Link\n",
        "\n",
        "https://github.com/tomasanthony/cs598-project\n"
      ],
      "metadata": {
        "id": "-CfIGmp3RecR"
      }
    }
  ]
}